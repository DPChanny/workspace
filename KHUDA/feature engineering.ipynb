{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5f88ce0-e4fd-4a2c-9ec4-283c20e949ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1       0.0       3   \n",
      "1            2       1.0       1   \n",
      "2            3       1.0       3   \n",
      "3            4       1.0       1   \n",
      "4            5       0.0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1309 entries, 0 to 417\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  1309 non-null   int64  \n",
      " 1   Survived     891 non-null    float64\n",
      " 2   Pclass       1309 non-null   int64  \n",
      " 3   Name         1309 non-null   object \n",
      " 4   Sex          1309 non-null   object \n",
      " 5   Age          1046 non-null   float64\n",
      " 6   SibSp        1309 non-null   int64  \n",
      " 7   Parch        1309 non-null   int64  \n",
      " 8   Ticket       1309 non-null   object \n",
      " 9   Fare         1308 non-null   float64\n",
      " 10  Cabin        295 non-null    object \n",
      " 11  Embarked     1307 non-null   object \n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 132.9+ KB\n",
      "PassengerId       0\n",
      "Survived        418\n",
      "Pclass            0\n",
      "Name              0\n",
      "Sex               0\n",
      "Age             263\n",
      "SibSp             0\n",
      "Parch             0\n",
      "Ticket            0\n",
      "Fare              1\n",
      "Cabin          1014\n",
      "Embarked          2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler, Normalizer, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # 경고 메시지 무시\n",
    "\n",
    "# titanic 데이터셋은 기존 대회에서 주어진 데이터셋으로 train, test가 분할되어 배포됨. \n",
    "# 두 개의 데이터셋을 불러와 concat()을 통해 합쳐야함.\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "# 데이터셋 합치기\n",
    "df = pd.concat([df_train, df_test], axis = 0)\n",
    "\n",
    "# 데이터셋 기본 정보 확인\n",
    "print(df.head())\n",
    "df.info()\n",
    "\n",
    "# 결측치 확인\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 데이터 복사본 생성해서 사용할 경우\n",
    "# df_copy = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e049d2b1-493b-4ece-81d0-c6ee206b48e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Age 결측치 처리 후\n",
      "Age 컬럼 결측치 개수: 0\n",
      "\n",
      "Embarked 결측치 처리 후\n",
      "Embarked 컬럼 결측치 개수: 0\n",
      "\n",
      "Cabin 결측치 처리 후\n",
      "Cabin 컬럼 결측치 개수: 0\n",
      "\n",
      "모든 결측치 처리 후 최종 확인\n",
      "PassengerId      0\n",
      "Survived       418\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin            0\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Age 결측치 처리: 중앙값으로 대체\n",
    "imputer_age = SimpleImputer(strategy='median')\n",
    "df['Age'] = imputer_age.fit_transform(df[['Age']])\n",
    "print(\"\\nAge 결측치 처리 후\")\n",
    "print(f\"Age 컬럼 결측치 개수: {df['Age'].isnull().sum()}\")\n",
    "\n",
    "# Embarked 결측치 처리: 최빈값으로 대체\n",
    "imputer_embarked = SimpleImputer(strategy='most_frequent')\n",
    "# .squeeze()를 사용하여 1차원 배열로 변환\n",
    "df['Embarked'] = imputer_embarked.fit_transform(df[['Embarked']]).squeeze()\n",
    "print(\"\\nEmbarked 결측치 처리 후\")\n",
    "print(f\"Embarked 컬럼 결측치 개수: {df['Embarked'].isnull().sum()}\")\n",
    "\n",
    "# Cabin 결측치 처리: 'N'으로 대체\n",
    "df['Cabin'] = df['Cabin'].fillna('N')\n",
    "print(\"\\nCabin 결측치 처리 후\")\n",
    "print(f\"Cabin 컬럼 결측치 개수: {df['Cabin'].isnull().sum()}\")\n",
    "\n",
    "print(\"\\n모든 결측치 처리 후 최종 확인\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdbbdcd2-4b35-402b-9b61-a8233aaec559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN 대체\n",
    "#\t결측치가 전체 데이터 중 5~10% 이내일 때 성능이 좋음\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "df_numeric_imputed = pd.DataFrame(imputer.fit_transform(df_numeric), columns=df_numeric.columns)\n",
    "\n",
    "# MICE 대체 (Multiple Imputation by Chained Equations)\n",
    "# 각 변수를 다른 변수로 예측하는 방식이므로, 변수 간 상관성이 높을수록 효과적\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "mice_imputer = IterativeImputer(random_state=42)\n",
    "df_numeric_mice = pd.DataFrame(mice_imputer.fit_transform(df_numeric), columns=df_numeric.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eab050c6-c504-43ad-a8e3-cd19c0cf06e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sex 레이블 인코딩 예시\n",
      "      Sex  Sex_encoded\n",
      "0    male            1\n",
      "1  female            0\n",
      "2  female            0\n",
      "3  female            0\n",
      "4    male            1\n",
      "인코딩된 값: ['female' 'male'] -> [0 1]\n",
      "\n",
      "Embarked 원-핫 인코딩 예시\n",
      "  Embarked  Embarked_C  Embarked_Q  Embarked_S\n",
      "0        S         0.0         0.0         1.0\n",
      "1        C         1.0         0.0         0.0\n",
      "2        S         0.0         0.0         1.0\n",
      "3        S         0.0         0.0         1.0\n",
      "4        S         0.0         0.0         1.0\n"
     ]
    }
   ],
   "source": [
    "# Sex 컬럼 레이블 인코딩\n",
    "# 'male'을 0, 'female'을 1 등으로 변환\n",
    "le = LabelEncoder() #인코더 생성\n",
    "df['Sex_encoded'] = le.fit_transform(df['Sex'])\n",
    "print(\"\\nSex 레이블 인코딩 예시\")\n",
    "print(df[['Sex', 'Sex_encoded']].head())\n",
    "print(f\"인코딩된 값: {le.classes_} -> {le.transform(le.classes_)}\") # 어떤 값이 어떻게 변환되었는지 확인\n",
    "\n",
    "# Embarked 컬럼 원-핫 인코딩\n",
    "# 원-핫 인코딩은 새로운 컬럼을 생성하므로, 기존 데이터프레임에 병합합니다.\n",
    "# drop_first=True로 설정하면 다중 공선성 문제를 피할 수 있지만, 여기서는 이해를 위해 False로 둡니다.\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "# 희소 행렬(sparse matrix)을 반환하지만, 이걸 일반적인 NumPy 배열로 바꾸기 위해 사용\n",
    "# 학습되지 않은 새로운 범주가 예측에 들어올 경우 오류를 내는 대신 0벡터로 처리함\n",
    "embarked_encoded = ohe.fit_transform(df[['Embarked']])\n",
    "\n",
    "# OneHotEncoder의 출력은 NumPy 배열이므로 DataFrame으로 변환\n",
    "# get_feature_names_out()을 사용하여 컬럼 이름 생성\n",
    "embarked_df = pd.DataFrame(embarked_encoded, columns=ohe.get_feature_names_out(['Embarked']))\n",
    "\n",
    "# 원본 데이터프레임과 병합\n",
    "df = pd.concat([df.reset_index(drop=True), embarked_df], axis=1)\n",
    "# 열 방향으로 병합\n",
    "\n",
    "print(\"\\nEmbarked 원-핫 인코딩 예시\")\n",
    "print(df[['Embarked', 'Embarked_C', 'Embarked_Q', 'Embarked_S']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc526c34-32a5-46f5-839d-0d3944529c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FamilySize 파생 변수 예시\n",
      "   SibSp  Parch  FamilySize\n",
      "0      1      0           2\n",
      "1      1      0           2\n",
      "2      0      0           1\n",
      "3      1      0           2\n",
      "4      0      0           1\n",
      "\n",
      "IsAlone 파생 변수 예시\n",
      "   FamilySize  IsAlone\n",
      "0           2        0\n",
      "1           2        0\n",
      "2           1        1\n",
      "3           2        0\n",
      "4           1        1\n",
      "\n",
      "Title 파생 변수 예시 및 분포\n",
      "Title\n",
      "Mr        757\n",
      "Miss      264\n",
      "Mrs       198\n",
      "Master     61\n",
      "Rare       29\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Title 레이블 인코딩 예시\n",
      "  Title  Title_encoded\n",
      "0    Mr              2\n",
      "1   Mrs              3\n",
      "2  Miss              1\n",
      "3   Mrs              3\n",
      "4    Mr              2\n"
     ]
    }
   ],
   "source": [
    "# FamilySize 파생 변수 생성\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "print(\"\\nFamilySize 파생 변수 예시\")\n",
    "print(df[['SibSp', 'Parch', 'FamilySize']].head())\n",
    "\n",
    "# IsAlone 파생 변수 생성\n",
    "# FamilySize가 1이면 1 (혼자), 아니면 0 (혼자가 아님)\n",
    "df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "print(\"\\nIsAlone 파생 변수 예시\")\n",
    "print(df[['FamilySize', 'IsAlone']].head())\n",
    "\n",
    "# Title 파생 변수 생성 (이름에서 호칭 추출)\n",
    "# 정규표현식을 사용하여 이름에서 호칭 추출\n",
    "df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "# 드물게 나타나는 호칭들을 'Rare'로 묶기\n",
    "rare_titles = ['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona']\n",
    "df['Title'] = df['Title'].replace(rare_titles, 'Rare')\n",
    "df['Title'] = df['Title'].replace('Mlle', 'Miss') # Mlle는 Miss로\n",
    "df['Title'] = df['Title'].replace('Ms', 'Miss')   # Ms도 Miss로\n",
    "df['Title'] = df['Title'].replace('Mme', 'Mrs')   # Mme는 Mrs로\n",
    "\n",
    "print(\"\\nTitle 파생 변수 예시 및 분포\")\n",
    "print(df['Title'].value_counts())\n",
    "\n",
    "# Title도 범주형이므로 레이블 인코딩\n",
    "df['Title_encoded'] = le.fit_transform(df['Title']) # 기존 LabelEncoder 재활용\n",
    "print(\"\\nTitle 레이블 인코딩 예시\")\n",
    "print(df[['Title', 'Title_encoded']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff2be1c9-252f-4a79-be72-94bc95ae3f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# family_size를 가지고 family group이라는 새로운 범주형 범수 생성 가능\n",
    "def map_family_group(size):\n",
    "    if size == 1:\n",
    "        return 'Solo'\n",
    "    elif 2 <= size <= 4:\n",
    "        return 'Small'\n",
    "    else:\n",
    "        return 'Large'\n",
    "        \n",
    "df['FamilyGroup'] = df['FamilySize'].apply(map_family_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a6ecd0d-69a1-47b1-bcc6-5f7af75099b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "StandardScaler 적용 후\n",
      "   Age_standard_scaled  Fare_standard_scaled\n",
      "0            -0.581628             -0.503402\n",
      "1             0.658652              0.734222\n",
      "2            -0.271558             -0.490356\n",
      "3             0.426099              0.382778\n",
      "4             0.426099             -0.487940\n",
      "\n",
      "MinMaxScaler 적용 후\n",
      "   Age_minmax_scaled  Fare_minmax_scaled\n",
      "0           0.273456            0.014151\n",
      "1           0.473882            0.139136\n",
      "2           0.323563            0.015469\n",
      "3           0.436302            0.103644\n",
      "4           0.436302            0.015713\n"
     ]
    }
   ],
   "source": [
    "# 스케일링할 숫자형 특성들 정의\n",
    "numeric_features_to_scale = ['Age', 'Fare']\n",
    "\n",
    "# 1. StandardScaler (표준화) 적용\n",
    "scaler_standard = StandardScaler()\n",
    "# fit_transform은 2D 배열을 기대하므로, 데이터프레임 슬라이싱 형태 [[]] 유지\n",
    "scaled_data_standard = scaler_standard.fit_transform(df[numeric_features_to_scale])\n",
    "#fit은 데이터의 평균과 표준편차를 학습하고, transform은 학습된 값으로 데이터를 변환\n",
    "df_standard_scaled = pd.DataFrame(scaled_data_standard, columns=numeric_features_to_scale)\n",
    "df_standard_scaled = df_standard_scaled.add_suffix('_standard_scaled') # 모든 컬럼 이름에 접미사 추가\n",
    "#변환된 데이터를 새로운 데이터프레임으로\n",
    "\n",
    "# 원본 데이터프레임에 병합\n",
    "df = pd.concat([df.reset_index(drop=True), df_standard_scaled], axis=1)\n",
    "\n",
    "print(\"\\nStandardScaler 적용 후\")\n",
    "print(df[[f'{col}_standard_scaled' for col in numeric_features_to_scale]].head())\n",
    "\n",
    "\n",
    "# 2. MinMaxScaler (정규화) 적용\n",
    "min_max_scaler = MinMaxScaler()\n",
    "scaled_data_minmax = min_max_scaler.fit_transform(df[numeric_features_to_scale]) # 변환된 NumPy 배열 / fit_transform()은 2차원 배열 기대 -> df \n",
    "\n",
    "df_minmax_scaled = pd.DataFrame(scaled_data_minmax, columns=numeric_features_to_scale)\n",
    "# 변환된 데이터를 데이터프레임으로 변환\n",
    "# 새로 생성될 데이터프레임 칼럼 이름 지정\n",
    "df_minmax_scaled = df_minmax_scaled.add_suffix('_minmax_scaled')\n",
    "# 모든 칼럼 뒤에 접미사 추가\n",
    "\n",
    "\n",
    "\n",
    "# 원본 데이터프레임에 병합\n",
    "df = pd.concat([df.reset_index(drop=True), df_minmax_scaled], axis=1)\n",
    "#기존 인덱스 버리고, 새로운 인덱스 추가\n",
    "\n",
    "print(\"\\nMinMaxScaler 적용 후\")\n",
    "print(df[[f'{col}_minmax_scaled' for col in numeric_features_to_scale]].head())\n",
    "\n",
    "# RobustScaler, MaxAbsScaler, Normalizer도 유사한 방식으로 적용가능\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
